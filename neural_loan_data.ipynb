{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD6P7Z79OWSTbkWgNTOjhM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChiaoYunTing/ADA-Group15/blob/main/neural_loan_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqxLbGnjZKuM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "A9JrKYy-ZQt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload an in-built Python (OK semi-in-built) dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_excel('loan_data.xlsx')"
      ],
      "metadata": {
        "id": "FBqCFV4ZZSn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = df.pop('loan_is_bad')\n",
        "features = df\n",
        "tf_dataset = tf.data.Dataset.from_tensor_slices((features.values, target.values))"
      ],
      "metadata": {
        "id": "AzLOxtofZUYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = len(list(tf_dataset))\n",
        "train_size = int(n * 0.8)\n",
        "train_dataset = tf_dataset.take(train_size)\n",
        "test_dataset = tf_dataset.skip(train_size)"
      ],
      "metadata": {
        "id": "WAs_27RBZWjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batch = train_dataset.batch(50) # batch size = 50\n",
        "features, labels = next(iter(train_batch)) # iterate through each batch at training time\n",
        "\n",
        "# print the first 20 records (rows) of features and labels\n",
        "print(features[0:20])\n",
        "print(labels[0:20])"
      ],
      "metadata": {
        "id": "eQ0m6x7gZYQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "feature_count = features.shape[1]#determine number of features\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, activation='relu', input_shape=(feature_count,)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])#dropout rate could be 0.2-0.5 and it is for reducing overfitting"
      ],
      "metadata": {
        "id": "QToxaci7ZZ0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001,  weight_decay=0.005),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])#learning_rate and weight_decay are for reducing overfitting(idk whether it is overlapped with dropout rate)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "mbsmrQHfZcsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset, epochs=10)"
      ],
      "metadata": {
        "id": "9ZXO9onmZeO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_dataset = test_dataset.batch(50)\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset, verbose=2)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "GBuQKoZ6ZfxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictions = model.predict(test_dataset)\n",
        "for pred, real in zip(predictions, test_labels):\n",
        "    predicted_label = (pred > 0.5).astype(int)\n",
        "    print(f\"Predicted: {predicted_label};    Real: {real}\")\n",
        "test_loss, test_accuracy = model.evaluate(test_dataset, verbose=2)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "9P5bIoo7Zhce"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}